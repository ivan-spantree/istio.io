{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivan-spantree/istio.io/blob/master/apps/append-only-table-compaction-script/append_only_table_compaction_script/append_only_table_compaction_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to PostgreSQL"
      ],
      "metadata": {
        "id": "yVhY8M61b8xi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej4XdtFybuEi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlalchemy as db\n",
        "import json\n",
        "import os\n",
        "from sqlalchemy.orm import Session, close_all_sessions\n",
        "from sqlalchemy.ext.automap import automap_base\n",
        "from getpass import getpass\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "POSTGRES_HOST = \"db.qmyiliblwjiahsiuqnwr.supabase.co\"\n",
        "POSTGRES_PORT = 5432\n",
        "POSTGRES_USER = \"postgres\"\n",
        "POSTGRES_DATABASE = \"postgres\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getenv(varname, getpass_message = None):\n",
        "  value = os.getenv(\"POSTGRES_PASSWORD\")\n",
        "  if not value:\n",
        "    getpass_message = getpass_message or f\"Enter {varname}\"\n",
        "    value = getpass(getpass_message)\n",
        "  return value\n",
        "\n",
        "POSTGRES_PASSWORD = getenv('POSTGRES_PASSWORD', 'Enter Postgres Password')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaCgkXAHaxYB",
        "outputId": "48b6f0bc-4513-4287-d953-3acbd2a433e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Postgres Password··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_url = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DATABASE}\"\n",
        "\n",
        "close_all_sessions()\n",
        "\n",
        "engine = db.create_engine(db_url, pool_timeout = 3, connect_args={\"connect_timeout\": 10})\n",
        "conn = engine.connect()\n",
        "\n",
        "Base = automap_base()\n",
        "Base.prepare(engine, schema=\"service_float_snapshot\")\n",
        "metadata = Base.metadata\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "tables_list = list(metadata.tables.keys())"
      ],
      "metadata": {
        "id": "dw1Vb0prcBK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve Row IDs to Delete from Raw Tables\n",
        "\n"
      ],
      "metadata": {
        "id": "RJNEgPOvcDzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_tables_list = [table_name.split(\".\")[1] for table_name in tables_list if len(table_name.split(\".\")) > 1 and list(table_name.split(\".\")[1])[0] == \"_\"]\n",
        "\n",
        "table_id_columns = {\n",
        "    \"accounts\": \"account_id\",\n",
        "    \"clients\": \"client_id\",\n",
        "    \"departments\": \"department_id\",\n",
        "    \"logged_time\": \"logged_time_id\",\n",
        "    \"milestones\": \"milestone_id\",\n",
        "    \"people\": \"people_id\",\n",
        "    \"projects\": \"project_id\",\n",
        "    \"public_holidays\": \"id\",\n",
        "    \"tasks\": \"task_id\",\n",
        "    \"team_holidays\": \"holiday_id\",\n",
        "    \"time_off\": \"timeoff_id\",\n",
        "    \"time_off_types\": \"timeoff_type_id\"\n",
        "}\n",
        "# \"people_department\" has a compound id of \"_airbyte_people_hashid\" and \"airbyte_department_hashid\""
      ],
      "metadata": {
        "id": "rTnAUw4f2Iul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_raw_ids = {}\n",
        "\n",
        "for table_name in raw_tables_list:\n",
        "  float_table_equivalent = \"_\".join(table_name.split(\"_\")[3:])\n",
        "\n",
        "  # \"phases\" and \"statuses\" exist in the raw Airbyte tables but have no rows and don't exist as Float tables\n",
        "  if float_table_equivalent != \"phases\" and float_table_equivalent != \"statuses\":\n",
        "\n",
        "    query = db.text(f\"\"\"SELECT\n",
        "                    _airbyte_ab_id\n",
        "                    FROM (\n",
        "                            SELECT\n",
        "                                _airbyte_ab_id, row_number() OVER (\n",
        "                                    PARTITION BY _airbyte_data ->> '{table_id_columns[float_table_equivalent]}', md5(_airbyte_data::text)\n",
        "                                    ORDER BY _airbyte_emitted_at ASC\n",
        "                                ) AS duplicated_row_index\n",
        "                            FROM\n",
        "                                service_float_snapshot.{table_name}\n",
        "                        ) sub\n",
        "                    WHERE duplicated_row_index > 1\"\"\")\n",
        "\n",
        "    df = pd.read_sql(query, conn)\n",
        "\n",
        "    duplicate_raw_ids[float_table_equivalent] = df[\"_airbyte_ab_id\"].tolist()"
      ],
      "metadata": {
        "id": "4o9PcQxkcBSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(duplicate_raw_ids['logged_time'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4bxO4dBD1wL",
        "outputId": "b1cd2230-e8ef-4dd1-a33b-77ff42ab0588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete Duplicate Rows from Raw Tables"
      ],
      "metadata": {
        "id": "N2ULgqQfDZXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE_CHUNK_SIZE = getenv('DELETE_CHUNK_SIZE')\n",
        "DELETE_CHUNK_SIZE = 1000\n",
        "\n",
        "for float_table_name, ids_to_delete in duplicate_raw_ids.items():\n",
        "  full_table_name = f\"service_float_snapshot._airbyte_raw_{float_table_name}\"\n",
        "  table = metadata.tables[full_table_name]\n",
        "\n",
        "  for start in range(0, len(ids_to_delete), DELETE_CHUNK_SIZE):\n",
        "      end = start + DELETE_CHUNK_SIZE\n",
        "      ids_chunk = ids_to_delete[start:end]\n",
        "\n",
        "      delete_statement = db.delete(table).where(table.c._airbyte_ab_id.in_(ids_chunk))\n",
        "\n",
        "      try:\n",
        "        conn.execute(delete_statement)\n",
        "        conn.commit()\n",
        "\n",
        "        print(f\"Deleted {DELETE_CHUNK_SIZE} rows from {full_table_name}\")\n",
        "      except Exception as e:\n",
        "          # Rollback the transaction in case of an exception\n",
        "          conn.rollback()\n",
        "          print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "bJPP19j3Da3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete Duplicate Rows in Float Tables"
      ],
      "metadata": {
        "id": "KNRrGIsfgA4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_tables = table_id_columns.keys()\n",
        "float_columns = {}\n",
        "\n",
        "for table_name in float_tables:\n",
        "  query = db.text(f\"\"\"SELECT * FROM service_float_snapshot.{table_name} WHERE 1 = 0\"\"\")\n",
        "\n",
        "  df = pd.read_sql(query, conn)\n",
        "\n",
        "  all_columns_list = list(df.columns.values)\n",
        "  float_columns_list = [column_name for column_name in all_columns_list if column_name[0] != \"_\"]\n",
        "  float_columns[table_name] = float_columns_list"
      ],
      "metadata": {
        "id": "N3WJXfOv_jSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_ids = {}\n",
        "\n",
        "for float_table_name, float_columns_list in float_columns.items():\n",
        "  full_table_name = f\"service_float_snapshot.{float_table_name}\"\n",
        "  table = metadata.tables[full_table_name]\n",
        "\n",
        "  reformatted_columns_list = \", \".join(float_columns_list)\n",
        "\n",
        "  query = db.text(f\"\"\"SELECT\n",
        "                    _airbyte_ab_id\n",
        "                    FROM (\n",
        "                            SELECT\n",
        "                                _airbyte_ab_id, row_number() OVER (\n",
        "                                    PARTITION BY {reformatted_columns_list}\n",
        "                                    ORDER BY _airbyte_emitted_at ASC\n",
        "                                ) AS duplicated_row_index\n",
        "                            FROM\n",
        "                                {full_table_name}\n",
        "                        ) sub\n",
        "                    WHERE duplicated_row_index > 1\"\"\")\n",
        "\n",
        "  df = pd.read_sql(query, conn)\n",
        "\n",
        "  duplicate_ids[float_table_name] = df[\"_airbyte_ab_id\"].tolist()"
      ],
      "metadata": {
        "id": "jIMl7C1nEeFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE_CHUNK_SIZE = getenv('DELETE_CHUNK_SIZE')\n",
        "DELETE_CHUNK_SIZE = 1000\n",
        "\n",
        "for float_table_name, ids_to_delete in duplicate_ids.items():\n",
        "  full_table_name = f\"service_float_snapshot.{float_table_name}\"\n",
        "  table = metadata.tables[full_table_name]\n",
        "\n",
        "  for start in range(0, len(ids_to_delete), DELETE_CHUNK_SIZE):\n",
        "      end = start + DELETE_CHUNK_SIZE\n",
        "      ids_chunk = ids_to_delete[start:end]\n",
        "\n",
        "      delete_statement = db.delete(table).where(table.c._airbyte_ab_id.in_(ids_chunk))\n",
        "\n",
        "      try:\n",
        "        conn.execute(delete_statement)\n",
        "        conn.commit()\n",
        "\n",
        "        print(f\"Deleted {DELETE_CHUNK_SIZE} rows from {full_table_name}\")\n",
        "      except Exception as e:\n",
        "          # Rollback the transaction in case of an exception\n",
        "          conn.rollback()\n",
        "          print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "4kOo8B3dHcG4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}